# Algorithmes g√©n√©tiques

## 1. Introduction

Les **algorithmes g√©n√©tiques (AG)** font partie de la famille des **algorithmes √©volutionnaires**, c‚Äôest-√†-dire des m√©thodes d‚Äôoptimisation qui s‚Äôinspirent du **processus de s√©lection naturelle** d√©crit par Charles Darwin.  
L‚Äôid√©e est de **faire √©voluer une population de solutions candidates** en appliquant des m√©canismes biologiques simul√©s : **s√©lection**, **croisement** et **mutation**.

√Ä chaque g√©n√©ration, les solutions **les plus adapt√©es** (selon une mesure appel√©e _fitness_) sont **conserv√©es, crois√©es et l√©g√®rement modifi√©es**, dans l‚Äôespoir de produire des **descendants meilleurs**.  
Ce processus est **r√©p√©t√© sur plusieurs g√©n√©rations**, jusqu‚Äô√† ce qu‚Äôon obtienne une solution satisfaisante.

### Quand utiliser un algorithme g√©n√©tique ?

Les AG sont particuli√®rement utiles lorsque :

- L‚Äôespace de recherche est **trop grand** pour √™tre explor√© de mani√®re exhaustive
- Aucune **formule math√©matique explicite** ne permet d‚Äôoptimiser le probl√®me
- Le probl√®me pr√©sente de **nombreux optima locaux** (non convexe, discontinu‚Ä¶)
- Les **donn√©es sont bruit√©es**, incompl√®tes ou difficiles √† mod√©liser
- On cherche une **solution approch√©e** acceptable plut√¥t qu‚Äôun optimum exact

Exemples : conception automatique, planification, ing√©nierie, jeux, optimisation combinatoire...

## 2. Principes biologiques simul√©s

Un algorithme g√©n√©tique simule une **√©volution artificielle** au sein d‚Äôune population.  
Chaque √©l√©ment de cette population repr√©sente une **solution possible** au probl√®me, cod√©e sous une forme manipulable (binaire, tableau, permutation‚Ä¶).

Voici les principaux concepts biologiques mod√©lis√©s :

### 2.1. **Population**

- Ensemble de **solutions candidates** (appel√©es _individus_ ou _chromosomes_)
- Taille constante ou variable selon les g√©n√©rations
- Chaque individu repr√©sente **un point de l‚Äôespace de recherche**

### 2.2. **G√®nes et codage**

- Un **g√®ne** est une unit√© d‚Äôinformation de la solution (bit, nombre, symbole‚Ä¶)
- L‚Äôensemble des g√®nes forme le **g√©notype** (ex : une cha√Æne binaire)
- Ce g√©notype est **d√©cod√©** pour produire le **ph√©notype** (la solution r√©elle dans le probl√®me)

üí° Le choix du codage a un **impact important sur la performance** de l‚Äôalgorithme.

### 2.3. **Fonction d‚Äô√©valuation (fitness)**

- Permet de mesurer la **qualit√© d‚Äôun individu**
- Plus un individu a une fitness √©lev√©e, plus il est **susceptible de se reproduire**
- La fitness est sp√©cifique au probl√®me (ex : score √† maximiser, co√ªt √† minimiser)

### 2.4. **S√©lection**

- M√©canisme qui **favorise les meilleurs individus** (ou les plus adapt√©s) pour la reproduction
- Objectif : **transmettre les bons g√®nes** √† la g√©n√©ration suivante
- M√©thodes courantes : **roulette**, **tournoi**, **rang**, **√©lite**

### 2.5. **Croisement (recombinaison)**

- Combine les g√®nes de deux parents pour cr√©er un ou plusieurs **descendants**
- Peut se faire en un point, deux points, ou uniform√©ment
- Objectif : **m√©langer l'information g√©n√©tique** de mani√®re constructive

### 2.6. **Mutation**

- Modifie **al√©atoirement un ou plusieurs g√®nes** d‚Äôun individu
- Permet d‚Äô**introduire de la diversit√©** et d‚Äô√©viter le blocage dans des optima locaux
- Taux de mutation faible (typiquement entre 1 % et 5 %)

### 2.7. **Remplacement (survie)**

- Apr√®s g√©n√©ration des descendants, on d√©cide qui **reste dans la population**
- Soit on **remplace enti√®rement** la population, soit on garde une **partie des meilleurs**
- L‚Äô**√©litisme** consiste √† **conserver automatiquement les meilleurs individus**

## 3. Sch√©ma g√©n√©ral d‚Äôun algorithme g√©n√©tique

```text
1. Initialiser une population de solutions al√©atoires
2. √âvaluer la fitness de chaque individu
3. R√©p√©ter jusqu‚Äô√† condition d‚Äôarr√™t :
    a. S√©lectionner des individus selon leur fitness
    b. Croiser certains couples pour produire des descendants
    c. Appliquer des mutations al√©atoires
    d. √âvaluer les nouveaux individus
    e. Mettre √† jour la population (avec ou sans remplacement)
```

### Explication √©tape par √©tape

#### **1. Initialisation**

- G√©n√©ration al√©atoire d‚Äôune **population initiale** d‚Äôindividus (solutions)
- Chaque individu est une solution **cod√©e selon un sch√©ma choisi** (binaire, tableau de r√©els, permutations, etc.)
- Taille typique : entre **20 et 500 individus**

#### **2. √âvaluation**

- On **calcule la fitness** de chaque individu √† l‚Äôaide de la fonction d‚Äô√©valuation d√©finie
- Cette √©tape **guide l‚Äô√©volution** : seuls les plus adapt√©s seront s√©lectionn√©s

#### **3. Boucle principale (√©volution)**

La boucle √©volutive peut durer :

- un **nombre fixe de g√©n√©rations**
- ou jusqu‚Äô√† **atteinte d‚Äôun score cible**, ou **stagnation des performances**

##### **a. S√©lection**

- Choix des **parents** en fonction de leur fitness
- M√©thodes courantes :
  - **Roulette** : probabilit√© proportionnelle √† la fitness
  - **Tournoi** : s√©lection des meilleurs parmi des sous-groupes al√©atoires
  - **√âlite** : les meilleurs passent automatiquement √† la g√©n√©ration suivante

##### **b. Croisement (recombinaison)**

- Cr√©ation de nouveaux individus en **croisant les g√®nes de deux parents**
- Objectif : **combiner les bonnes caract√©ristiques**
- Types de croisement :
  - Un point
  - Deux points
  - Uniforme (chaque g√®ne vient au hasard de l‚Äôun ou l‚Äôautre parent)

##### **c. Mutation**

- Modification al√©atoire d‚Äôun ou plusieurs g√®nes
- Maintient une **diversit√© g√©n√©tique** dans la population
- Emp√™che l‚Äôalgorithme de **se bloquer dans un optimum local**
- Le **taux de mutation** est faible mais crucial

##### **d. √âvaluation des descendants**

- On **√©value la fitness des nouveaux individus**
- Ceux-ci seront ensuite potentiellement int√©gr√©s dans la population

##### **e. Mise √† jour de la population**

- **Remplacement** : quels individus seront pr√©sents √† la g√©n√©ration suivante ?
  - **Remplacement complet** : seuls les enfants survivent
  - **Remplacement partiel** : on garde les meilleurs de l‚Äôancienne population
  - **√âlitisme** : les meilleurs individus ne sont jamais supprim√©s

### Condition d'arr√™t

L‚Äô√©volution s‚Äôarr√™te g√©n√©ralement lorsque :

- un **nombre maximal de g√©n√©rations** est atteint
- une **solution satisfaisante** est trouv√©e
- la population **ne progresse plus** (convergence)

## 4. Exemple simple : maximiser une fonction

### Probl√®me

On cherche √† **maximiser la fonction** :

```
f(x) = x¬≤
```

pour `x` ‚àà [0, 31], c‚Äôest-√†-dire pour `x` cod√© sur **5 bits** (de `00000` √† `11111`).

Chaque individu est donc repr√©sent√© par **un entier compris entre 0 et 31**, que l‚Äôon peut manipuler **comme une suite binaire de 5 bits**.

L‚Äôobjectif est que l‚Äôalgorithme √©volue vers des individus ayant des valeurs proches de **31**, puisque `f(x)` est croissante et maximale en `x = 31`.

### √âtapes de l‚Äôalgorithme g√©n√©tique

1. **Population initiale** : 6 entiers al√©atoires entre 0 et 31
2. **√âvaluation (fitness)** : on calcule `x¬≤` pour chaque individu
3. **S√©lection** : on choisit deux parents avec une probabilit√© **proportionnelle √† leur fitness**
4. **Croisement** : on coupe al√©atoirement les bits entre deux parents pour cr√©er un descendant
5. **Mutation** : un bit al√©atoire peut √™tre invers√© avec une petite probabilit√©
6. **Remplacement** : les enfants et une partie des parents forment la nouvelle population

### Code comment√©

```python
import random

# Fonction de fitness = objectif √† maximiser
def fitness(x):
    return x * x
```

- On maximise `f(x) = x¬≤`
- Un x proche de 31 aura une fitness √©lev√©e (jusqu‚Äô√† 961)

```python
# S√©lection proportionnelle √† la fitness (roulette)
def selection(pop):
    return random.choices(pop, weights=[fitness(x) for x in pop], k=2)
```

- On choisit deux parents dans la population
- Les individus avec une meilleure fitness ont **plus de chances** d‚Äô√™tre choisis

```python
# Croisement √† un point (bitmask entre les deux parents)
def crossover(p1, p2):
    point = random.randint(1, 4)  # point de croisement entre 1 et 4 (sur 5 bits)
    mask = (1 << point) - 1       # ex : point = 3 ‚Üí mask = 000111
    return (p1 & mask) | (p2 & ~mask)
```

- Combine les bits de `p1` et `p2` pour former un **enfant**
- Les bits **√† droite** viennent de `p1`, les bits **√† gauche** de `p2`

```python
# Mutation : inversion d‚Äôun bit avec probabilit√© de 10 %
def mutate(x):
    if random.random() < 0.1:
        bit = 1 << random.randint(0, 4)  # choisir un bit parmi les 5
        return x ^ bit                   # inverse ce bit avec XOR
    return x
```

- Permet d‚Äôintroduire un peu d‚Äô**al√©a g√©n√©tique**
- √âvite de **se bloquer dans des optima locaux**

```python
def algo_genetique():
    population = [random.randint(0, 31) for _ in range(6)]  # population initiale
    for generation in range(20):  # nombre de g√©n√©rations
        new_population = []
        for _ in range(3):  # 3 paires d‚Äôindividus ‚Üí 6 au total
            p1, p2 = selection(population)
            enfant = crossover(p1, p2)
            enfant = mutate(enfant)
            new_population.extend([p1, enfant])  # on garde le parent + l‚Äôenfant
        population = new_population  # mise √† jour
    return max(population, key=fitness)  # meilleur individu final
```

### R√©sultat attendu

```python
print(algo_genetique())
```

- Affiche une **valeur de `x`** dans `[0, 31]`
- Apr√®s 20 g√©n√©rations, on obtient **souvent un `x` proche de 31**, donc **pr√®s de l‚Äôoptimum global**

### Ce que montre cet exemple

- M√™me avec un probl√®me tr√®s simple et un **encodage direct**, l‚Äôalgorithme g√©n√©tique **parvient √† converger vers la meilleure solution**
- Il montre la **puissance du principe d‚Äô√©volution**, m√™me sans connaissance explicite du maximum
- Il est **facile √† modifier** pour maximiser d‚Äôautres fonctions, explorer d'autres encodages (r√©els, permutations...)

## 5. Exemple avanc√© : Algorithme g√©n√©tique pour le sac √† dos 0/1

### Probl√®me

On dispose de `n` objets, chacun avec :

- un **poids** `poids[i]`
- une **valeur** `valeurs[i]`

Capacit√© maximale du sac : `W`  
Objectif : **choisir un sous-ensemble d‚Äôobjets** de valeur maximale sans d√©passer la capacit√© du sac.

### Codage g√©n√©tique

Chaque solution est repr√©sent√©e par un **chromosome binaire de longueur `n`** :

- `1` ‚Üí l‚Äôobjet est s√©lectionn√©
- `0` ‚Üí l‚Äôobjet est ignor√©

Exemple : `10110` signifie : on prend l‚Äôobjet 1, 3 et 4.

### Fonction de fitness

On calcule :

- la **somme des valeurs** des objets s√©lectionn√©s
- si la **somme des poids d√©passe `W`**, on **p√©nalise fortement** la solution (ex : fitness = 0)

### Code Python comment√©

```python
import random

# Donn√©es du probl√®me
valeurs = [60, 100, 120]
poids   = [10, 20, 30]
W       = 50
n       = len(valeurs)
```

### Fonction de fitness

```python
def fitness(chromosome):
    total_val = total_pds = 0
    for i in range(n):
        if chromosome[i] == 1:
            total_val += valeurs[i]
            total_pds += poids[i]
    if total_pds > W:
        return 0  # solution invalide
    return total_val
```

- On **r√©compense les solutions valides** en retournant leur valeur totale
- On **√©limine les solutions invalides** (poids > W)

### G√©n√©ration d‚Äôun individu al√©atoire

```python
def random_individu():
    return [random.randint(0, 1) for _ in range(n)]
```

### S√©lection (roulette)

```python
def selection(pop):
    scores = [fitness(ind) for ind in pop]
    total = sum(scores)
    if total == 0:
        return random.sample(pop, 2)
    return random.choices(pop, weights=scores, k=2)
```

- Si tout le monde a une fitness nulle (au d√©but), on choisit deux parents au hasard
- Sinon, on utilise une **s√©lection proportionnelle √† la fitness**

### Croisement (√† un point)

```python
def crossover(p1, p2):
    point = random.randint(1, n - 1)
    return p1[:point] + p2[point:]
```

### Mutation (inversion al√©atoire d‚Äôun bit)

```python
def mutate(individu, taux=0.1):
    return [
        bit if random.random() > taux else 1 - bit
        for bit in individu
    ]
```

### Algorithme principal

```python
def algo_genetique_sacados(generations=50, taille_pop=10):
    population = [random_individu() for _ in range(taille_pop)]

    for _ in range(generations):
        nouvelle_pop = []
        for _ in range(taille_pop // 2):
            p1, p2 = selection(population)
            enfant1 = mutate(crossover(p1, p2))
            enfant2 = mutate(crossover(p2, p1))
            nouvelle_pop.extend([enfant1, enfant2])
        population = nouvelle_pop

    meilleur = max(population, key=fitness)
    return meilleur, fitness(meilleur)
```

### Exemple d‚Äôutilisation

```python
sol, val = algo_genetique_sacados()
print("Meilleure solution trouv√©e :", sol)
print("Valeur totale :", val)
```

### Explication des r√©sultats

- Le programme affiche un **vecteur binaire**, indiquant quels objets sont pris
- La valeur totale affich√©e est **la meilleure trouv√©e** apr√®s plusieurs g√©n√©rations
- Pour les donn√©es `[60, 100, 120]` et `W = 50`, la solution optimale est de prendre objets 2 et 3 ‚Üí total 220

### Remarques

- Cet algorithme **approxime** une bonne solution, sans garantie d‚Äôoptimalit√©
- Il peut √™tre am√©lior√© avec :
  - **√©litisme** (garder les meilleurs individus)
  - **croisement plus intelligent**
  - **mutation adaptative**
  - **diversit√© contr√¥l√©e** pour √©viter la convergence pr√©matur√©e

## 6. √âtude de complexit√©

L‚Äô**algorithme g√©n√©tique** est un algorithme **probabiliste** et **heuristique** :  
il **n‚Äôa pas de garantie th√©orique d‚Äôoptimalit√©**, mais offre souvent **des r√©sultats efficaces en pratique**.  
Sa complexit√© d√©pend principalement de **param√®tres r√©glables**.

### 6.1. Param√®tres cl√©s

| Param√®tre | Description                          |
| --------- | ------------------------------------ |
| `N`       | Taille de la population              |
| `G`       | Nombre de g√©n√©rations                |
| `T_eval`  | Co√ªt d‚Äô√©valuation d‚Äôun individu      |
| `n`       | Longueur du chromosome (nb de g√®nes) |

### 6.2. Complexit√© temporelle

√Ä chaque g√©n√©ration :

- On s√©lectionne `N` individus
- On effectue `N/2` croisements ‚Üí `N` enfants
- On applique la mutation
- On √©value les `N` enfants

Donc **par g√©n√©ration** :

```
O(N √ó T_eval)
```

Et pour `G` g√©n√©rations :

```
O(G √ó N √ó T_eval)
```

#### üí° Cas courants

| Probl√®me                    | `T_eval` approximatif        | Complexit√© totale      |
| --------------------------- | ---------------------------- | ---------------------- |
| Fonction simple (`x¬≤`)      | `O(1)`                       | `O(G √ó N)`             |
| Sac √† dos (`n` objets)      | `O(n)` par individu          | `O(G √ó N √ó n)`         |
| Probl√®me combinatoire (TSP) | `O(n)` ou `O(n¬≤)` selon √©val | `O(G √ó N √ó n)` ou `n¬≤` |

### 6.3. Complexit√© spatiale

On stocke :

- La **population courante** de `N` individus
- Chaque individu est un chromosome de taille `n`

Donc :

```
O(N √ó n)
```

> La m√©moire utilis√©e reste mod√©r√©e, m√™me pour des tailles importantes.

### 6.4. Remarques pratiques

- La **qualit√© des solutions** d√©pend plus des **param√®tres** (mutation, s√©lection, diversit√©‚Ä¶) que de la complexit√© brute
- Les **AG sont faciles √† parall√©liser**, car l‚Äô√©valuation des individus est ind√©pendante
- L‚Äô**analyse th√©orique** est difficile car la convergence d√©pend de la **stochastique** de l‚Äô√©volution


### 6.5. En r√©sum√©

| Aspect              | Valeur typique                                                |
| ------------------- | ------------------------------------------------------------- |
| Temps (th√©orique)   | `O(G √ó N √ó T_eval)`                                           |
| Espace              | `O(N √ó n)`                                                    |
| Optimalit√© garantie | ‚ùå (pas de garantie)                                          |
| Avantages           | Robuste, simple, flexible, global                             |
| Limites             | Lent pour des √©valuations co√ªteuses, sensibilit√© aux r√©glages |
